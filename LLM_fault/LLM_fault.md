# LLM fault

猜测：LLM欺诈，在<font color='red'>脱敏策略</font>的实践应用，在现在的研究中多是对其视为一种攻击方式。

一些想法：

- 使用LLM去生成脱敏后的文本，安全性如何保障，LLm对于输入的内容是如何处理的，会保存记录吗？不保存记录的话，推理的过程信息会被逆向还原出来吗？
- 【**问题**】搜不到相关的研究，从LLM安全上以及LLM生成虚假信息检测上的研究入手。
- 应用：将原文本进行敏感数据检测之后，将检测出来的敏感信息遮掩，然后以填空的形式问询LLM来生成语义一致性较高的脱敏后的文本，这里面的方法需要注意，需要强语义一致性的文本生成能力的LLM，且遮掩后的数据需要进行审核，防止敏感信息传递到LLM中。